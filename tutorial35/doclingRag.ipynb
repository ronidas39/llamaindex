{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roni/Documents/GitHub/llamaindex/tutorial35/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<00:00, 116869.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.readers.docling import DoclingReader\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.core import VectorStoreIndex\n",
    "llm=OpenAI(model=\"gpt-4o\")\n",
    "embed_model=OpenAIEmbedding()\n",
    "reader=DoclingReader()\n",
    "node_parser=MarkdownNodeParser()\n",
    "docs=reader.load_data(\"https://arxiv.org/pdf/2411.05442\")\n",
    "index=VectorStoreIndex.from_documents(documents=docs,transformations=[node_parser],embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine=index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=query_engine.query(\"what is discussed here write in well structed points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- The development of a cybersecurity chatbot using Large Language Model (LLM) technology is outlined.\\n- The architecture of the chatbot, named IntellBot, involves three main phases:\\n  1. **Creation of the Security Knowledge Base**: This includes data collection, document loading, text segmentation, conversion of textual data into numerical format, and storage of embedding vectors in a vector store.\\n  2. **Generation of Query Response Interface**: A user-friendly interface was developed using Streamlit to allow users to pose security-related queries.\\n  3. **Evaluation of Chatbot Responses**: The responses generated by the chatbot are evaluated against those generated by human experts using indirect proof and cosine similarity.\\n- Data collection involved using various document types such as PDFs, CSVs, JSONs, and URLs to create a comprehensive dataset.\\n- The dataset includes:\\n  - Cybersecurity books and Advanced Persistent Threat (APT) reports.\\n  - Data from VirusTotal, including malicious file hashes.\\n  - Information from websites like KrebsOnSecurity and Malwarebytes.\\n  - Vulnerability details from the National Vulnerability Database (NVD).\\n  - Security-related blogs from platforms like HackerNews and BleepingComputer.\\n- Data preprocessing steps were implemented to improve data quality, including removing duplicates and cleaning HTML data.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The usage of Large Language Models (LLMs) in this context involves the development of a cyber security chatbot called IntellBot. The LLM technology is utilized to generate responses to security-related queries posed by users through a user-friendly interface. The chatbot's architecture includes creating a security knowledge base, generating a query response interface, and evaluating the chatbot's responses against those generated by human experts. The LLM aids in converting textual data into numerical format, storing embedding vectors, and facilitating the response generation process.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=query_engine.query(\"what is the usage of LLM here?\")\n",
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langchain is utilized to build a cyber security chatbot by leveraging its modular and extensible framework. It simplifies the creation of applications that use language models by providing tools for loading and managing these models, tokenizing input text, and handling common operations. In this specific application, Langchain's components such as prompts, document loaders, agents, and chains are employed. Prompts guide the language model's responses, document loaders prepare documents for input, agents act as intermediaries to execute tasks, and chains represent the sequence of operations for interacting with the language model. These components enhance the chatbot's capabilities, particularly in preserving conversational context and integrating knowledge bases.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=query_engine.query(\"how langchain is used here?\")\n",
    "response.response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0e21d1ab7cf66e97f165278cfa4becfa1a766969b88c91c2a42de17e11b08ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
